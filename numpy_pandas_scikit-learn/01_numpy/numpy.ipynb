{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy Essentials for Machine Learning (Beginner-friendly)\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Learn how to create and work with NumPy arrays\n",
    "- Use basic array math, broadcasting, and reshaping\n",
    "- Apply simple linear algebra and statistics used in ML workflows\n",
    "\n",
    "**Prerequisites:** Python basics, pip-install NumPy\n",
    "\n",
    "**Estimated Time:** ~30 minutes\n",
    "\n",
    "---\n",
    "\n",
    "NumPy is a foundational library for numerical computing in Python. This notebook focuses on hands-on examples and short explanations aimed at beginners. Where advanced topics are shown, they are marked as optional."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.476684Z",
     "start_time": "2025-09-11T05:57:06.422713Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.3.3\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Array Creation and Basic Properties\n",
    "\n",
    "Understanding how to create and inspect arrays is fundamental to ML workflows."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.495012Z",
     "start_time": "2025-09-11T05:57:06.491318Z"
    }
   },
   "source": [
    "# Different ways to create arrays (common in ML)\n",
    "\n",
    "# From lists (loading data)\n",
    "data_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "arr_from_list = np.array(data_list)\n",
    "print(\"From list:\")\n",
    "print(arr_from_list)\n",
    "print(f\"Shape: {arr_from_list.shape}, Dtype: {arr_from_list.dtype}\\n\")\n",
    "\n",
    "# Zeros (weight initialization)\n",
    "weights = np.zeros((3, 4))\n",
    "print(\"Zeros (weight initialization):\")\n",
    "print(weights)\n",
    "print(f\"Shape: {weights.shape}\\n\")\n",
    "\n",
    "# Random arrays (data generation, weight initialization)\n",
    "random_data = np.random.randn(100, 5)  # 100 samples, 5 features\n",
    "print(\"Random data (first 5 rows):\")\n",
    "print(random_data[:5])\n",
    "print(f\"Shape: {random_data.shape}\\n\")\n",
    "\n",
    "# Identity matrix (useful for regularization)\n",
    "identity = np.eye(3)\n",
    "print(\"Identity matrix:\")\n",
    "print(identity)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From list:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Shape: (3, 3), Dtype: int64\n",
      "\n",
      "Zeros (weight initialization):\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "Shape: (3, 4)\n",
      "\n",
      "Random data (first 5 rows):\n",
      "[[ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337]\n",
      " [-0.23413696  1.57921282  0.76743473 -0.46947439  0.54256004]\n",
      " [-0.46341769 -0.46572975  0.24196227 -1.91328024 -1.72491783]\n",
      " [-0.56228753 -1.01283112  0.31424733 -0.90802408 -1.4123037 ]\n",
      " [ 1.46564877 -0.2257763   0.0675282  -1.42474819 -0.54438272]]\n",
      "Shape: (100, 5)\n",
      "\n",
      "Identity matrix:\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.505254Z",
     "start_time": "2025-09-11T05:57:06.502050Z"
    }
   },
   "source": [
    "# Array properties essential for ML\n",
    "sample_array = np.random.randn(32, 10, 8)  # Batch size 32, sequence length 10, features 8\n",
    "\n",
    "print(\"Array Properties (typical ML batch):\")\n",
    "print(f\"Shape: {sample_array.shape} (batch_size, seq_len, features)\")\n",
    "print(f\"Number of dimensions: {sample_array.ndim}\")\n",
    "print(f\"Total elements: {sample_array.size}\")\n",
    "print(f\"Data type: {sample_array.dtype}\")\n",
    "print(f\"Memory usage: {sample_array.nbytes} bytes\")\n",
    "print(f\"Memory usage: {sample_array.nbytes / 1024:.2f} KB\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Properties (typical ML batch):\n",
      "Shape: (32, 10, 8) (batch_size, seq_len, features)\n",
      "Number of dimensions: 3\n",
      "Total elements: 2560\n",
      "Data type: float64\n",
      "Memory usage: 20480 bytes\n",
      "Memory usage: 20.00 KB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Array Indexing and Slicing\n",
    "\n",
    "Critical for data manipulation, batch processing, and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.532093Z",
     "start_time": "2025-09-11T05:57:06.527072Z"
    }
   },
   "source": [
    "# Create sample data representing a batch of images\n",
    "# Shape: (batch_size, height, width, channels)\n",
    "batch_images = np.random.randint(0, 256, size=(8, 28, 28, 3))\n",
    "\n",
    "print(\"Batch of images shape:\", batch_images.shape)\n",
    "print(\"\\nIndexing and Slicing Examples:\")\n",
    "\n",
    "# Get first image\n",
    "first_image = batch_images[0]\n",
    "print(f\"First image shape: {first_image.shape}\")\n",
    "\n",
    "# Get first 4 images (mini-batch)\n",
    "mini_batch = batch_images[:4]\n",
    "print(f\"Mini-batch shape: {mini_batch.shape}\")\n",
    "\n",
    "# Get red channel from all images\n",
    "red_channel = batch_images[:, :, :, 0]\n",
    "print(f\"Red channel shape: {red_channel.shape}\")\n",
    "\n",
    "# Get center crop (common preprocessing)\n",
    "center_crop = batch_images[:, 7:21, 7:21, :]\n",
    "print(f\"Center crop shape: {center_crop.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images shape: (8, 28, 28, 3)\n",
      "\n",
      "Indexing and Slicing Examples:\n",
      "First image shape: (28, 28, 3)\n",
      "Mini-batch shape: (4, 28, 28, 3)\n",
      "Red channel shape: (8, 28, 28)\n",
      "Center crop shape: (8, 14, 14, 3)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.542705Z",
     "start_time": "2025-09-11T05:57:06.539278Z"
    }
   },
   "source": [
    "# Boolean indexing (filtering data)\n",
    "scores = np.array([85, 92, 78, 96, 88, 73, 91, 82])\n",
    "names = np.array(['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace', 'Henry'])\n",
    "\n",
    "print(\"Original scores:\", scores)\n",
    "print(\"Names:\", names)\n",
    "\n",
    "# Filter high performers (score > 85)\n",
    "high_performers = scores > 85\n",
    "print(f\"\\nHigh performers mask: {high_performers}\")\n",
    "print(f\"High performer scores: {scores[high_performers]}\")\n",
    "print(f\"High performer names: {names[high_performers]}\")\n",
    "\n",
    "# Multiple conditions\n",
    "good_range = (scores >= 80) & (scores <= 90)\n",
    "print(f\"\\nScores in 80-90 range: {scores[good_range]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original scores: [85 92 78 96 88 73 91 82]\n",
      "Names: ['Alice' 'Bob' 'Charlie' 'Diana' 'Eve' 'Frank' 'Grace' 'Henry']\n",
      "\n",
      "High performers mask: [False  True False  True  True False  True False]\n",
      "High performer scores: [92 96 88 91]\n",
      "High performer names: ['Bob' 'Diana' 'Eve' 'Grace']\n",
      "\n",
      "Scores in 80-90 range: [85 88 82]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Array Operations and Broadcasting\n",
    "\n",
    "Broadcasting is crucial for efficient ML computations and is used across numerical computing libraries and tools."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.561661Z",
     "start_time": "2025-09-11T05:57:06.557236Z"
    }
   },
   "source": [
    "# Element-wise operations (fundamental to neural networks)\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "b = np.array([[2, 2, 2], [3, 3, 3]])\n",
    "\n",
    "print(\"Array a:\")\n",
    "print(a)\n",
    "print(\"\\nArray b:\")\n",
    "print(b)\n",
    "\n",
    "print(\"\\nElement-wise operations:\")\n",
    "print(\"Addition (a + b):\")\n",
    "print(a + b)\n",
    "\n",
    "print(\"\\nMultiplication (a * b):\")\n",
    "print(a * b)\n",
    "\n",
    "print(\"\\nSquare (a**2):\")\n",
    "print(a**2)\n",
    "\n",
    "# Activation functions\n",
    "print(\"\\nCommon activation functions:\")\n",
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"ReLU (max(0, x)): {np.maximum(0, x)}\")\n",
    "print(f\"Sigmoid: {1 / (1 + np.exp(-x))}\")\n",
    "print(f\"Tanh: {np.tanh(x)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array a:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Array b:\n",
      "[[2 2 2]\n",
      " [3 3 3]]\n",
      "\n",
      "Element-wise operations:\n",
      "Addition (a + b):\n",
      "[[3 4 5]\n",
      " [7 8 9]]\n",
      "\n",
      "Multiplication (a * b):\n",
      "[[ 2  4  6]\n",
      " [12 15 18]]\n",
      "\n",
      "Square (a**2):\n",
      "[[ 1  4  9]\n",
      " [16 25 36]]\n",
      "\n",
      "Common activation functions:\n",
      "Input: [-2 -1  0  1  2]\n",
      "ReLU (max(0, x)): [0 0 0 1 2]\n",
      "Sigmoid: [0.11920292 0.26894142 0.5        0.73105858 0.88079708]\n",
      "Tanh: [-0.96402758 -0.76159416  0.          0.76159416  0.96402758]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.587929Z",
     "start_time": "2025-09-11T05:57:06.573348Z"
    }
   },
   "source": [
    "# Broadcasting examples (very important for ML)\n",
    "print(\"Broadcasting Examples:\")\n",
    "\n",
    "# Example 1: Adding bias to all samples\n",
    "features = np.random.randn(100, 5)  # 100 samples, 5 features\n",
    "bias = np.array([0.1, -0.2, 0.3, -0.1, 0.2])  # bias for each feature\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Bias shape: {bias.shape}\")\n",
    "\n",
    "# Broadcasting adds bias to each sample\n",
    "features_with_bias = features + bias\n",
    "print(f\"Result shape: {features_with_bias.shape}\")\n",
    "print(f\"First sample before: {features[0]}\")\n",
    "print(f\"First sample after: {features_with_bias[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Example 2: Normalizing features (mean centering)\n",
    "data = np.random.randn(1000, 3) * 10 + 5  # Add some offset and scale\n",
    "print(f\"\\nOriginal data shape: {data.shape}\")\n",
    "print(f\"Original means: {np.mean(data, axis=0)}\")\n",
    "print(f\"Original stds: {np.std(data, axis=0)}\")\n",
    "\n",
    "# Normalize (broadcasting)\n",
    "mean = np.mean(data, axis=0)  # Shape: (3,)\n",
    "std = np.std(data, axis=0)    # Shape: (3,)\n",
    "normalized_data = (data - mean) / std  # Broadcasting!\n",
    "\n",
    "print(f\"\\nNormalized means: {np.mean(normalized_data, axis=0)}\")\n",
    "print(f\"Normalized stds: {np.std(normalized_data, axis=0)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcasting Examples:\n",
      "Features shape: (100, 5)\n",
      "Bias shape: (5,)\n",
      "Result shape: (100, 5)\n",
      "First sample before: [-1.33767419  0.61217162  0.56928932  0.07166855 -0.24237546]\n",
      "First sample after: [-1.23767419  0.41217162  0.86928932 -0.02833145 -0.04237546]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Original data shape: (1000, 3)\n",
      "Original means: [4.3688771 5.4340328 5.8957205]\n",
      "Original stds: [ 9.97976302  9.78954254 10.3014967 ]\n",
      "\n",
      "Normalized means: [-1.52045043e-16 -2.39586129e-16 -4.27546887e-16]\n",
      "Normalized stds: [1. 1. 1.]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.607972Z",
     "start_time": "2025-09-11T05:57:06.601534Z"
    }
   },
   "source": [
    "# Broadcasting rules visualization\n",
    "print(\"Broadcasting Rules Examples:\")\n",
    "\n",
    "# Rule: Arrays are aligned from the rightmost dimension\n",
    "examples = [\n",
    "    ((3, 4), (4,)),      # (3,4) + (4,) -> (3,4)\n",
    "    ((2, 3, 4), (4,)),   # (2,3,4) + (4,) -> (2,3,4)\n",
    "    ((2, 3, 4), (3, 4)), # (2,3,4) + (3,4) -> (2,3,4)\n",
    "    ((2, 1, 4), (3, 4)), # (2,1,4) + (3,4) -> (2,3,4)\n",
    "]\n",
    "\n",
    "for shape1, shape2 in examples:\n",
    "    a = np.ones(shape1)\n",
    "    b = np.ones(shape2)\n",
    "    result = a + b\n",
    "    print(f\"\\n{shape1} + {shape2} -> {result.shape}\")\n",
    "    print(\"\\nArray A:\")\n",
    "    print(a)\n",
    "    print(\"\\nArray B:\")\n",
    "    print(b)\n",
    "    print(\"\\nResult:\")\n",
    "    print(result)\n",
    "    print(\"-\"*50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcasting Rules Examples:\n",
      "\n",
      "(3, 4) + (4,) -> (3, 4)\n",
      "\n",
      "Array A:\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "Array B:\n",
      "[1. 1. 1. 1.]\n",
      "\n",
      "Result:\n",
      "[[2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "(2, 3, 4) + (4,) -> (2, 3, 4)\n",
      "\n",
      "Array A:\n",
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]]\n",
      "\n",
      "Array B:\n",
      "[1. 1. 1. 1.]\n",
      "\n",
      "Result:\n",
      "[[[2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]]\n",
      "\n",
      " [[2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]]]\n",
      "--------------------------------------------------\n",
      "\n",
      "(2, 3, 4) + (3, 4) -> (2, 3, 4)\n",
      "\n",
      "Array A:\n",
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]]\n",
      "\n",
      "Array B:\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "Result:\n",
      "[[[2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]]\n",
      "\n",
      " [[2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]]]\n",
      "--------------------------------------------------\n",
      "\n",
      "(2, 1, 4) + (3, 4) -> (2, 3, 4)\n",
      "\n",
      "Array A:\n",
      "[[[1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]]]\n",
      "\n",
      "Array B:\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "Result:\n",
      "[[[2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]]\n",
      "\n",
      " [[2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2.]]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Algebra Operations\n",
    "\n",
    "Essential for understanding neural network computations, matrix multiplications, and transformations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.617396Z",
     "start_time": "2025-09-11T05:57:06.614223Z"
    }
   },
   "source": [
    "# Matrix multiplication (core of neural networks)\n",
    "print(\"Matrix Multiplication Examples:\")\n",
    "\n",
    "# Simulate a simple neural network layer\n",
    "# Input: batch_size=32, input_features=10\n",
    "# Layer: input_features=10, output_features=5\n",
    "batch_size, input_features, output_features = 32, 10, 5\n",
    "\n",
    "X = np.random.randn(batch_size, input_features)  # Input data\n",
    "W = np.random.randn(input_features, output_features)  # Weights\n",
    "b = np.random.randn(output_features)  # Bias\n",
    "\n",
    "print(f\"Input X shape: {X.shape}\")\n",
    "print(f\"Weights W shape: {W.shape}\")\n",
    "print(f\"Bias b shape: {b.shape}\")\n",
    "\n",
    "# Forward pass: Y = XW + b\n",
    "Y = np.dot(X, W) + b  # or X @ W + b\n",
    "print(f\"Output Y shape: {Y.shape}\")\n",
    "\n",
    "print(f\"\\nFirst sample input: {X[0][:5]}...\")  # Show first 5 features\n",
    "print(f\"First sample output: {Y[0]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiplication Examples:\n",
      "Input X shape: (32, 10)\n",
      "Weights W shape: (10, 5)\n",
      "Bias b shape: (5,)\n",
      "Output Y shape: (32, 5)\n",
      "\n",
      "First sample input: [ 0.40265698 -0.07046034  0.42698368 -0.65456494  0.11033543]...\n",
      "First sample output: [ 1.32621282  1.70173192 -0.74400113 -1.45980749 -1.53939884]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.657461Z",
     "start_time": "2025-09-11T05:57:06.642706Z"
    }
   },
   "source": [
    "# Different matrix operations\n",
    "A = np.random.randn(3, 4)\n",
    "B = np.random.randn(4, 2)\n",
    "\n",
    "print(\"Matrix Operations:\")\n",
    "print(f\"A shape: {A.shape}\")\n",
    "print(f\"B shape: {B.shape}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "C = A @ B  # Same as np.dot(A, B)\n",
    "print(f\"A @ B shape: {C.shape}\")\n",
    "\n",
    "# Transpose (very common in ML)\n",
    "A_T = A.T\n",
    "print(f\"A transpose shape: {A_T.shape}\")\n",
    "\n",
    "# Element-wise vs matrix multiplication\n",
    "square_matrix = np.random.randn(3, 3)\n",
    "print(f\"\\nSquare matrix shape: {square_matrix.shape}\")\n",
    "print(f\"Element-wise square: {(square_matrix * square_matrix).shape}\")\n",
    "print(f\"Matrix multiplication: {(square_matrix @ square_matrix).shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Operations:\n",
      "A shape: (3, 4)\n",
      "B shape: (4, 2)\n",
      "A @ B shape: (3, 2)\n",
      "A transpose shape: (4, 3)\n",
      "\n",
      "Square matrix shape: (3, 3)\n",
      "Element-wise square: (3, 3)\n",
      "Matrix multiplication: (3, 3)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.669841Z",
     "start_time": "2025-09-11T05:57:06.664911Z"
    }
   },
   "source": [
    "# Advanced linear algebra (useful for understanding ML algorithms)\n",
    "print(\"Advanced Linear Algebra:\")\n",
    "\n",
    "# Create a symmetric matrix (common in optimization)\n",
    "A = np.random.randn(4, 4)\n",
    "symmetric_A = A + A.T\n",
    "\n",
    "print(f\"Matrix A shape: {symmetric_A.shape}\")\n",
    "\n",
    "# Eigenvalues and eigenvectors (PCA, optimization)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(symmetric_A)\n",
    "print(f\"Eigenvalues: {eigenvalues}\")\n",
    "print(f\"Eigenvectors shape: {eigenvectors.shape}\")\n",
    "\n",
    "# Matrix norms (regularization)\n",
    "print(\"\\nMatrix norms:\")\n",
    "print(f\"Frobenius norm: {np.linalg.norm(A, 'fro'):.4f}\")\n",
    "print(f\"L2 norm: {np.linalg.norm(A, 2):.4f}\")\n",
    "\n",
    "# Determinant and inverse\n",
    "det_A = np.linalg.det(symmetric_A)\n",
    "print(f\"\\nDeterminant: {det_A:.4f}\")\n",
    "\n",
    "if abs(det_A) > 1e-10:  # Check if invertible\n",
    "    inv_A = np.linalg.inv(symmetric_A)\n",
    "    print(f\"Inverse exists, shape: {inv_A.shape}\")\n",
    "    # Verify: A @ A^(-1) should be identity\n",
    "    identity_check = symmetric_A @ inv_A\n",
    "    print(f\"A @ A^(-1) close to identity: {np.allclose(identity_check, np.eye(4))}\")\n",
    "else:\n",
    "    print(\"Matrix is singular (not invertible)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Linear Algebra:\n",
      "Matrix A shape: (4, 4)\n",
      "Eigenvalues: [ 4.3549979   1.80615905 -2.23164492 -2.91563732]\n",
      "Eigenvectors shape: (4, 4)\n",
      "\n",
      "Matrix norms:\n",
      "Frobenius norm: 3.1701\n",
      "L2 norm: 2.4230\n",
      "\n",
      "Determinant: 51.1803\n",
      "Inverse exists, shape: (4, 4)\n",
      "A @ A^(-1) close to identity: True\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Operations and Aggregations\n",
    "\n",
    "Critical for data analysis, loss computation, and model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.771175Z",
     "start_time": "2025-09-11T05:57:06.752980Z"
    }
   },
   "source": [
    "# Statistical operations along different axes\n",
    "# Simulate prediction scores for classification\n",
    "# Shape: (batch_size, num_classes)\n",
    "predictions = np.random.randn(100, 5)  # 100 samples, 5 classes\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(\"\\nStatistical Operations:\")\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"Overall mean: {np.mean(predictions):.4f}\")\n",
    "print(f\"Overall std: {np.std(predictions):.4f}\")\n",
    "print(f\"Min value: {np.min(predictions):.4f}\")\n",
    "print(f\"Max value: {np.max(predictions):.4f}\")\n",
    "\n",
    "# Statistics along axes\n",
    "print(f\"\\nMean per class (axis=0): {np.mean(predictions, axis=0)}\")\n",
    "print(f\"Mean per sample (axis=1) shape: {np.mean(predictions, axis=1).shape}\")\n",
    "\n",
    "# Useful for softmax and classification\n",
    "max_per_sample = np.max(predictions, axis=1, keepdims=True)\n",
    "print(f\"\\nMax per sample shape (keepdims=True): {max_per_sample.shape}\")\n",
    "print(f\"Max per sample shape (keepdims=False): {np.max(predictions, axis=1).shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (100, 5)\n",
      "\n",
      "Statistical Operations:\n",
      "Overall mean: 0.0075\n",
      "Overall std: 0.9992\n",
      "Min value: -3.3295\n",
      "Max value: 2.4184\n",
      "\n",
      "Mean per class (axis=0): [ 0.0430433  -0.01403904 -0.1310505   0.07978231  0.05988469]\n",
      "Mean per sample (axis=1) shape: (100,)\n",
      "\n",
      "Max per sample shape (keepdims=True): (100, 1)\n",
      "Max per sample shape (keepdims=False): (100,)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.800124Z",
     "start_time": "2025-09-11T05:57:06.795239Z"
    }
   },
   "source": [
    "# Practical ML examples\n",
    "print(\"Practical ML Statistical Operations:\")\n",
    "\n",
    "# 1. Softmax implementation\n",
    "def softmax(x):\n",
    "    \"\"\"Numerically stable softmax\"\"\"\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "logits = np.random.randn(5, 3)  # 5 samples, 3 classes\n",
    "probabilities = softmax(logits)\n",
    "\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Probabilities shape: {probabilities.shape}\")\n",
    "print(f\"Probabilities sum per sample: {np.sum(probabilities, axis=1)}\")\n",
    "print(f\"First sample probabilities: {probabilities[0]}\")\n",
    "\n",
    "# 2. Accuracy calculation\n",
    "true_labels = np.array([0, 1, 2, 1, 0])\n",
    "predicted_labels = np.argmax(probabilities, axis=1)\n",
    "\n",
    "accuracy = np.mean(true_labels == predicted_labels)\n",
    "print(f\"\\nTrue labels: {true_labels}\")\n",
    "print(f\"Predicted labels: {predicted_labels}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Practical ML Statistical Operations:\n",
      "Logits shape: (5, 3)\n",
      "Probabilities shape: (5, 3)\n",
      "Probabilities sum per sample: [1. 1. 1. 1. 1.]\n",
      "First sample probabilities: [0.37378617 0.48353105 0.14268279]\n",
      "\n",
      "True labels: [0 1 2 1 0]\n",
      "Predicted labels: [1 0 0 1 0]\n",
      "Accuracy: 0.40\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.809937Z",
     "start_time": "2025-09-11T05:57:06.805980Z"
    }
   },
   "source": [
    "# Loss function implementations\n",
    "print(\"Common Loss Functions:\")\n",
    "\n",
    "# Mean Squared Error (regression)\n",
    "y_true = np.array([1.5, 2.3, 3.1, 4.2, 5.0])\n",
    "y_pred = np.array([1.2, 2.1, 3.4, 4.0, 5.2])\n",
    "\n",
    "mse = np.mean((y_true - y_pred)**2)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "print(f\"True values: {y_true}\")\n",
    "print(f\"Predicted values: {y_pred}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Cross-entropy loss (classification)\n",
    "def cross_entropy_loss(y_true_labels, y_pred_probs):\n",
    "    \"\"\"Cross-entropy loss for classification\"\"\"\n",
    "    # Convert labels to one-hot if needed\n",
    "    n_classes = y_pred_probs.shape[1]\n",
    "    y_true_onehot = np.eye(n_classes)[y_true_labels]\n",
    "\n",
    "    # Clip predictions to avoid log(0)\n",
    "    y_pred_clipped = np.clip(y_pred_probs, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # Calculate cross-entropy per sample and average\n",
    "    per_sample = np.sum(y_true_onehot * np.log(y_pred_clipped), axis=1)\n",
    "    loss = np.mean(np.negative(per_sample))\n",
    "    return loss\n",
    "\n",
    "ce_loss = cross_entropy_loss(true_labels, probabilities)\n",
    "print(f\"\\nCross-entropy loss: {ce_loss:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Loss Functions:\n",
      "True values: [1.5 2.3 3.1 4.2 5. ]\n",
      "Predicted values: [1.2 2.1 3.4 4.  5.2]\n",
      "MSE: 0.0600\n",
      "RMSE: 0.2449\n",
      "MAE: 0.2400\n",
      "\n",
      "Cross-entropy loss: 1.0208\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Array Reshaping and Manipulation\n",
    "\n",
    "Essential for preparing data for neural networks and handling different tensor shapes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.829639Z",
     "start_time": "2025-09-11T05:57:06.824330Z"
    }
   },
   "source": [
    "# Reshaping operations (very common in deep learning)\n",
    "print(\"Array Reshaping:\")\n",
    "\n",
    "# Original data: flattened images\n",
    "flattened_images = np.random.randint(0, 256, size=(100, 784))  # 100 images, 28x28 pixels\n",
    "print(f\"Flattened images shape: {flattened_images.shape}\")\n",
    "\n",
    "# Reshape to image format\n",
    "images = flattened_images.reshape(100, 28, 28)\n",
    "print(f\"Reshaped to images: {images.shape}\")\n",
    "\n",
    "# Add channel dimension (for CNN)\n",
    "images_with_channel = images.reshape(100, 28, 28, 1)\n",
    "print(f\"With channel dimension: {images_with_channel.shape}\")\n",
    "\n",
    "# Or using -1 for automatic calculation\n",
    "auto_reshape = flattened_images.reshape(100, 28, 28, -1)\n",
    "print(f\"Auto reshape (-1): {auto_reshape.shape}\")\n",
    "\n",
    "# Flatten back\n",
    "flattened_again = images_with_channel.reshape(100, -1)\n",
    "print(f\"Flattened again: {flattened_again.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Reshaping:\n",
      "Flattened images shape: (100, 784)\n",
      "Reshaped to images: (100, 28, 28)\n",
      "With channel dimension: (100, 28, 28, 1)\n",
      "Auto reshape (-1): (100, 28, 28, 1)\n",
      "Flattened again: (100, 784)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.849093Z",
     "start_time": "2025-09-11T05:57:06.841073Z"
    }
   },
   "source": [
    "# Axis manipulation\n",
    "print(\"Axis Manipulation:\")\n",
    "\n",
    "# Sample data: batch of sequences\n",
    "sequences = np.random.randn(32, 50, 128)  # batch_size, seq_len, features\n",
    "print(f\"Original shape: {sequences.shape}\")\n",
    "\n",
    "# Transpose (swap axes)\n",
    "transposed = sequences.transpose(1, 0, 2)  # seq_len, batch_size, features\n",
    "print(f\"Transposed: {transposed.shape}\")\n",
    "\n",
    "# Add new axis\n",
    "with_new_axis = sequences[:, :, :, np.newaxis]\n",
    "print(f\"With new axis: {with_new_axis.shape}\")\n",
    "\n",
    "# Squeeze (remove dimensions of size 1)\n",
    "squeezed = np.squeeze(with_new_axis)\n",
    "print(f\"Squeezed: {squeezed.shape}\")\n",
    "\n",
    "# Expand dimensions\n",
    "expanded = np.expand_dims(sequences, axis=0)\n",
    "print(f\"Expanded (axis=0): {expanded.shape}\")\n",
    "\n",
    "expanded_last = np.expand_dims(sequences, axis=-1)\n",
    "print(f\"Expanded (axis=-1): {expanded_last.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axis Manipulation:\n",
      "Original shape: (32, 50, 128)\n",
      "Transposed: (50, 32, 128)\n",
      "With new axis: (32, 50, 128, 1)\n",
      "Squeezed: (32, 50, 128)\n",
      "Expanded (axis=0): (1, 32, 50, 128)\n",
      "Expanded (axis=-1): (32, 50, 128, 1)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.886900Z",
     "start_time": "2025-09-11T05:57:06.882553Z"
    }
   },
   "source": [
    "# Concatenation and stacking (combining data)\n",
    "print(\"Concatenation and Stacking:\")\n",
    "\n",
    "# Create sample batches\n",
    "batch1 = np.random.randn(16, 10)  # 16 samples, 10 features\n",
    "batch2 = np.random.randn(16, 10)  # 16 samples, 10 features\n",
    "batch3 = np.random.randn(16, 10)  # 16 samples, 10 features\n",
    "\n",
    "print(f\"Batch 1 shape: {batch1.shape}\")\n",
    "print(f\"Batch 2 shape: {batch2.shape}\")\n",
    "print(f\"Batch 3 shape: {batch3.shape}\")\n",
    "\n",
    "# Concatenate along batch dimension\n",
    "combined_batches = np.concatenate([batch1, batch2, batch3], axis=0)\n",
    "print(f\"Combined batches: {combined_batches.shape}\")\n",
    "\n",
    "# Stack (creates new dimension)\n",
    "stacked_batches = np.stack([batch1, batch2, batch3], axis=0)\n",
    "print(f\"Stacked batches: {stacked_batches.shape}\")\n",
    "\n",
    "# Horizontal stack (features)\n",
    "features1 = np.random.randn(100, 5)\n",
    "features2 = np.random.randn(100, 3)\n",
    "combined_features = np.hstack([features1, features2])\n",
    "print(f\"\\nFeatures 1: {features1.shape}\")\n",
    "print(f\"Features 2: {features2.shape}\")\n",
    "print(f\"Combined features: {combined_features.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation and Stacking:\n",
      "Batch 1 shape: (16, 10)\n",
      "Batch 2 shape: (16, 10)\n",
      "Batch 3 shape: (16, 10)\n",
      "Combined batches: (48, 10)\n",
      "Stacked batches: (3, 16, 10)\n",
      "\n",
      "Features 1: (100, 5)\n",
      "Features 2: (100, 3)\n",
      "Combined features: (100, 8)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance and Memory Considerations\n",
    "\n",
    "Understanding NumPy performance is crucial for efficient ML workflows."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.941123Z",
     "start_time": "2025-09-11T05:57:06.897416Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "# Vectorization vs loops\n",
    "print(\"Performance Comparison: Vectorization vs Loops\")\n",
    "\n",
    "# Create large arrays\n",
    "size = 1000000\n",
    "a = np.random.randn(size)\n",
    "b = np.random.randn(size)\n",
    "\n",
    "# Method 1: Pure Python loop (slow)\n",
    "start_time = time.time()\n",
    "result_loop = []\n",
    "for i in range(min(10000, size)):  # Only do 10k for speed\n",
    "    result_loop.append(a[i] * b[i])\n",
    "loop_time = time.time() - start_time\n",
    "\n",
    "# Method 2: NumPy vectorization (fast)\n",
    "start_time = time.time()\n",
    "result_vectorized = a * b\n",
    "vectorized_time = time.time() - start_time\n",
    "\n",
    "print(f\"Loop time (10k elements): {loop_time:.6f} seconds\")\n",
    "print(f\"Vectorized time ({size} elements): {vectorized_time:.6f} seconds\")\n",
    "print(f\"Speedup factor: {loop_time / vectorized_time * (size/10000):.1f}x\")\n",
    "\n",
    "# Memory usage\n",
    "print(\"\\nMemory usage:\")\n",
    "print(f\"Array 'a' memory: {a.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Array 'b' memory: {b.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Result memory: {result_vectorized.nbytes / 1024 / 1024:.2f} MB\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Comparison: Vectorization vs Loops\n",
      "Loop time (10k elements): 0.002123 seconds\n",
      "Vectorized time (1000000 elements): 0.002605 seconds\n",
      "Speedup factor: 81.5x\n",
      "\n",
      "Memory usage:\n",
      "Array 'a' memory: 7.63 MB\n",
      "Array 'b' memory: 7.63 MB\n",
      "Result memory: 7.63 MB\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.966349Z",
     "start_time": "2025-09-11T05:57:06.945728Z"
    }
   },
   "source": [
    "# Memory layout and views vs copies\n",
    "print(\"Memory Layout and Views:\")\n",
    "\n",
    "# Original array\n",
    "original = np.random.randn(1000, 1000)\n",
    "print(f\"Original array memory: {original.nbytes / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# View (shares memory)\n",
    "view = original[::2, ::2]  # Every other element\n",
    "print(f\"View shares memory: {view.base is original}\")\n",
    "print(f\"View shape: {view.shape}\")\n",
    "\n",
    "# Copy (new memory)\n",
    "copy = original.copy()\n",
    "print(f\"Copy shares memory: {copy.base is original}\")\n",
    "print(f\"Copy memory: {copy.nbytes / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Demonstrate view behavior\n",
    "original[0, 0] = 999\n",
    "print(\"\\nAfter modifying original[0,0] = 999:\")\n",
    "print(f\"View[0,0] = {view[0, 0]} (should be 999 if it's a view)\")\n",
    "print(f\"Copy[0,0] = {copy[0, 0]} (should be original value)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Layout and Views:\n",
      "Original array memory: 7.63 MB\n",
      "View shares memory: True\n",
      "View shape: (500, 500)\n",
      "Copy shares memory: False\n",
      "Copy memory: 7.63 MB\n",
      "\n",
      "After modifying original[0,0] = 999:\n",
      "View[0,0] = 999.0 (should be 999 if it's a view)\n",
      "Copy[0,0] = 0.8779508901505022 (should be original value)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Working with other ML libraries (brief, framework-neutral)\n",
    "\n",
    "NumPy arrays are the common numerical representation used across many machine learning tools. The key things to check when preparing NumPy arrays for use with other tools are:\n",
    "\n",
    "- dtype: many tools prefer float32 for inputs and integer labels for classification targets\n",
    "- shape: confirm batch and feature dimensions (e.g., (batch_size, num_features))\n",
    "- no NaNs or infinite values\n",
    "\n",
    "Example checks and simple conversion:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T05:57:06.983285Z",
     "start_time": "2025-09-11T05:57:06.980549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Using NumPy arrays with other tools (framework-neutral):\")\n",
    "\n",
    "# Create sample data in NumPy\n",
    "numpy_data = np.random.randn(32, 10)\n",
    "numpy_labels = np.random.randint(0, 3, size=(32,))\n",
    "\n",
    "print(f\"NumPy data shape: {numpy_data.shape}\")\n",
    "print(f\"NumPy data dtype before: {numpy_data.dtype}\")\n",
    "\n",
    "# Convert to a common dtype for ML (float32 inputs, int64 labels)\n",
    "numpy_data = numpy_data.astype(np.float32)\n",
    "numpy_labels = numpy_labels.astype(np.int64)\n",
    "\n",
    "print(f\"NumPy data dtype after: {numpy_data.dtype}\")\n",
    "print(f\"NumPy labels dtype after: {numpy_labels.dtype}\")\n",
    "\n",
    "print(\"\\nChecklist before handing arrays to another tool:\")\n",
    "print(\" - Are shapes as expected? (batch, features)\")\n",
    "print(\" - Are dtypes appropriate? (e.g. float32 for inputs)\")\n",
    "print(\" - Are there NaNs or infinite values?\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NumPy arrays with other tools (framework-neutral):\n",
      "NumPy data shape: (32, 10)\n",
      "NumPy data dtype before: float64\n",
      "NumPy data dtype after: float32\n",
      "NumPy labels dtype after: int64\n",
      "\n",
      "Checklist before handing arrays to another tool:\n",
      " - Are shapes as expected? (batch, features)\n",
      " - Are dtypes appropriate? (e.g. float32 for inputs)\n",
      " - Are there NaNs or infinite values?\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "**What we've learned:**\n",
    "\n",
    "1. **Array Creation & Properties**: Understanding shapes, dtypes, and memory usage\n",
    "2. **Indexing & Slicing**: Essential for data manipulation and batch processing\n",
    "3. **Broadcasting**: Enables efficient operations without explicit loops\n",
    "4. **Linear Algebra**: Matrix operations that form the core of many ML models\n",
    "5. **Statistical Operations**: Computing metrics, losses, and aggregations\n",
    "6. **Reshaping**: Preparing data for different network architectures\n",
    "7. **Performance**: Vectorization and memory considerations\n",
    "8. **Tool Bridge**: How NumPy arrays are the common numerical format used by many ML tools\n",
    "\n",
    "**Key Patterns for ML:**\n",
    "- Use vectorized operations instead of loops\n",
    "- Understand broadcasting for efficient computations\n",
    "- Master axis-based operations for batch processing\n",
    "- Know when operations create views vs copies\n",
    "- Prepare data in NumPy before converting to other tools\n",
    "\n",
    "**Next Steps:**\n",
    "- Learn Pandas for structured data manipulation\n",
    "- Understand how these concepts translate to other numerical libraries\n",
    "- See how higher-level ML libraries mirror NumPy patterns\n",
    "\n",
    "NumPy is a foundational numerical library. Mastering these concepts will make it easier to learn higher-level tools that build on the same numerical principles.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
