{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dfca2fe",
   "metadata": {},
   "source": [
    "# Logistic Regression — Beginner Friendly Notebook\n",
    "**Audience:** Students new to classification and basic statistics.\n",
    "\n",
    "**What this notebook is for (plain language):**\n",
    "We will learn how to predict categories (like pass/fail, spam/ham) using *logistic regression*.\n",
    "You will see the concept of mapping linear scores into probabilities with the logistic (sigmoid) function, fit models, and evaluate them with clear metrics.\n",
    "\n",
    "**Prerequisites**\n",
    "- Basic Python and algebra.\n",
    "- Some familiarity with probabilities is helpful but not required.\n",
    "\n",
    "**Notebook structure**\n",
    "1. Intuition and a tiny synthetic example (1D).\n",
    "2. Logistic model: sigmoid & loss (explained simply).\n",
    "3. Hands-on with the Breast Cancer dataset.\n",
    "4. Evaluation: confusion matrix, ROC, precision-recall.\n",
    "5. Regularization and class imbalance.\n",
    "6. Calibration and practical advice.\n",
    "7. Exercises and glossary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510d503",
   "metadata": {},
   "source": [
    "## 1 — Intuition with a tiny example\n",
    "\n",
    "We create synthetic data where the probability of class 1 increases with a feature `x`. We'll fit logistic regression and plot predicted probability vs `x`.\n",
    "This shows why we use a sigmoid: outputs between 0 and 1 that we can interpret as probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a9518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic logistic example (1D)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "np.random.seed(0)\n",
    "\n",
    "# create data\n",
    "X = np.linspace(-6, 6, 200).reshape(-1,1)\n",
    "# true probability (sigmoid of a linear function)\n",
    "true_prob = 1 / (1 + np.exp(-0.8 * X.squeeze()))\n",
    "y = (np.random.rand(X.shape[0]) < true_prob).astype(int)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "clf.fit(X, y)\n",
    "prob_pred = clf.predict_proba(X)[:,1]\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, alpha=0.2, label='observed class (jittered)')\n",
    "plt.plot(X, prob_pred, color='red', label='predicted P(y=1)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability / class')\n",
    "plt.legend()\n",
    "plt.title('Synthetic logistic regression: probability curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a1649c",
   "metadata": {},
   "source": [
    "**Beginner explanation**:\n",
    "- Observations are 0 or 1 (class labels). The sigmoid maps a linear combination to probabilities between 0 and 1.\n",
    "- We can choose a cutoff (usually 0.5) to convert probabilities to class predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e524d4",
   "metadata": {},
   "source": [
    "## 2 — Logistic function and loss (short, non-technical)\n",
    "\n",
    "The logistic (sigmoid) function squashes any real number to the interval (0,1).  \n",
    "The learning procedure chooses parameters to make predicted probabilities match observed labels — this is done by maximizing the likelihood (or equivalently minimizing log-loss / cross-entropy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c646dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 — Hands-on: Breast cancer dataset (binary classification)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "df = data.frame.copy()\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Test accuracy:', clf.score(X_test, y_test))\n",
    "print('\\nClassification report:\\n', classification_report(y_test, clf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbd750",
   "metadata": {},
   "source": [
    "## 4 — Confusion matrix, probabilities, and thresholds\n",
    "\n",
    "A confusion matrix shows true positives/negatives and false positives/negatives.  \n",
    "Adjusting the threshold trades precision vs recall. We'll compute predicted probabilities and show the confusion matrix at 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix and probabilities\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "probs = clf.predict_proba(X_test)[:,1]\n",
    "pred50 = (probs >= 0.5).astype(int)\n",
    "cm = confusion_matrix(y_test, pred50)\n",
    "print('Confusion matrix (threshold=0.5):\\n', cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02ba6f",
   "metadata": {},
   "source": [
    "## 5 — ROC and Precision-Recall (intuition)\n",
    "\n",
    "- ROC curve: plots true positive rate vs false positive rate as threshold varies. AUC summarizes it.\n",
    "- Precision-Recall: preferred when the positive class is rare; shows precision for different recall levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9721b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and Precision-Recall curves\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "plt.plot(fpr, tpr, label=f'AUC={auc:.3f}')\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, probs)\n",
    "ap = average_precision_score(y_test, probs)\n",
    "plt.plot(recall, precision, label=f'AP={ap:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a3cdf",
   "metadata": {},
   "source": [
    "## 6 — Regularization and class imbalance (short)\n",
    "\n",
    "Logistic regression supports L1 and L2 penalties. When classes are imbalanced, consider `class_weight='balanced'` or resampling.\n",
    "We'll show a quick grid search for regularization strength using AUC as the metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84941fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick grid search for regularization (AUC)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C':[0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, scoring='roc_auc', cv=4)\n",
    "grid.fit(X_train, y_train)\n",
    "best = grid.best_estimator_\n",
    "print('Best params:', grid.best_params_)\n",
    "print('Test AUC (best):', roc_auc_score(y_test, best.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c892d7a0",
   "metadata": {},
   "source": [
    "## 7 — Calibration (why it matters briefly)\n",
    "\n",
    "If you want probabilities (not just labels) to be trustworthy, check calibration. Methods such as Platt scaling or isotonic regression adjust predicted probabilities to better match observed frequencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed5420",
   "metadata": {},
   "source": [
    "## 8 — Practical tips, glossary, and exercises\n",
    "\n",
    "**Tips**\n",
    "- For simple problems, logistic regression is fast and interpretable.\n",
    "- Always look at predicted probabilities, not just accuracy.\n",
    "- Choose evaluation metric according to the task (precision, recall, AUC, AP).\n",
    "\n",
    "**Glossary**\n",
    "- Precision: TP / (TP + FP) — when predicted positive, how often correct.\n",
    "- Recall: TP / (TP + FN) — of true positives, how many we found.\n",
    "- AUC: area under ROC — single number summary of separability.\n",
    "\n",
    "**Exercises**\n",
    "1. Try different thresholds and plot precision and recall vs threshold.\n",
    "2. Use `class_weight='balanced'` and observe changes in recall/precision.\n",
    "3. Calibrate the classifier using `CalibratedClassifierCV` and compare reliability.\n",
    "\n",
    "_End of beginner logistic regression notebook._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
