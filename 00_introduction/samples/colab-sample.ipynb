{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# 🌸 Your First ML Model in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CS-6140-ML-Fall-2025/TA-Classes/blob/main/introduction/samples/colab-sample.ipynb)\n",
    "\n",
    "**What you'll build**: A flower species classifier that predicts iris flowers from measurements.\n",
    "\n",
    "**How to use**:\n",
    "1. Click \"Open in Colab\" above\n",
    "2. Save a copy: File → Save a copy in Drive\n",
    "3. Run each cell: Click ▶️ or press Shift + Enter\n",
    "\n",
    "**Time needed**: 5-10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "imports"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported!\n",
      "🚀 Ready to build your ML model!\n"
     ]
    }
   ],
   "source": [
    "# Import what we need\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"✅ Libraries imported!\")\n",
    "print(\"🚀 Ready to build your ML model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## Step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌸 Loading iris flower dataset...\n",
      "📊 Loaded 150 flower samples\n",
      "🏷️ Species: [np.str_('setosa'), np.str_('versicolor'), np.str_('virginica')]\n",
      "📏 Features: sepal length, sepal width, petal length, petal width\n"
     ]
    }
   ],
   "source": [
    "# Load flower data\n",
    "print(\"🌸 Loading iris flower dataset...\")\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "print(f\"📊 Loaded {len(X)} flower samples\")\n",
    "print(f\"🏷️ Species: {list(data.target_names)}\")\n",
    "print(f\"📏 Features: sepal length, sepal width, petal length, petal width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## Step 3: Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "split_data"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Training set: 105 flowers\n",
      "🧪 Test set: 45 flowers\n"
     ]
    }
   ],
   "source": [
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"📚 Training set: {len(X_train)} flowers\")\n",
    "print(f\"🧪 Test set: {len(X_test)} flowers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4"
   },
   "source": [
    "## Step 4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Training machine learning model...\n",
      "✅ Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create and train the model\n",
    "print(\"🤖 Training machine learning model...\")\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5"
   },
   "source": [
    "## Step 5: Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "test_model"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Model accuracy: 100.0%\n",
      "📊 Great! The model can identify flower species!\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"🎯 Model accuracy: {accuracy:.1%}\")\n",
    "print(\"📊 Great! The model can identify flower species!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6"
   },
   "source": [
    "## Step 6: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "predict"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 Predicting new flowers...\n",
      "🌺 Flower 1: [5.1 3.5 1.4 0.2] → setosa\n",
      "🌺 Flower 2: [6.2 2.8 4.8 1.8] → virginica\n",
      "🌺 Flower 3: [5.7 2.8 4.1 1.3] → versicolor\n",
      "\n",
      "✨ Success! Your ML model is working!\n"
     ]
    }
   ],
   "source": [
    "# Try predicting new flowers\n",
    "print(\"🔮 Predicting new flowers...\")\n",
    "\n",
    "new_flowers = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],  # Small petals\n",
    "    [6.2, 2.8, 4.8, 1.8],  # Large petals\n",
    "    [5.7, 2.8, 4.1, 1.3]   # Medium petals\n",
    "])\n",
    "\n",
    "predictions = model.predict(new_flowers)\n",
    "\n",
    "for i, (flower, pred) in enumerate(zip(new_flowers, predictions)):\n",
    "    species = data.target_names[pred]\n",
    "    print(f\"🌺 Flower {i+1}: {flower} → {species}\")\n",
    "\n",
    "print(\"\\n✨ Success! Your ML model is working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_tip"
   },
   "source": [
    "## 🚀 Colab Tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "colab_features"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 PyTorch not installed (that's okay for this example!)\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "try:\n",
    "    import torch\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    print(f\"🔥 GPU available: {gpu_available}\")\n",
    "    if not gpu_available:\n",
    "        print(\"💡 Enable GPU: Runtime → Change runtime type → GPU\")\n",
    "except ImportError:\n",
    "    print(\"📦 PyTorch not installed (that's okay for this example!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "You built your first ML model in Google Colab!\n",
    "\n",
    "### What you learned:\n",
    "✅ Load data from sklearn  \n",
    "✅ Split data for training/testing  \n",
    "✅ Train a RandomForest model  \n",
    "✅ Test model accuracy  \n",
    "✅ Make predictions on new data  \n",
    "\n",
    "### Next steps:\n",
    "🚀 Try different algorithms  \n",
    "🚀 Work with your own datasets  \n",
    "🚀 Learn data visualization  \n",
    "🚀 Explore deep learning  \n",
    "\n",
    "**Happy learning!** 🎓✨"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
